{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Facial_key_points",
   "id": "e4100cc1776a19fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### IMPORT PACKAGES",
   "id": "88b4ada123ec75ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T18:15:45.897740Z",
     "start_time": "2024-09-22T18:15:44.942231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n",
    "# os.chdir('/Users/romankasichhwa/Desktop/Facial_key_points') #manage path accordingly!\n",
    "# print(os.getcwd())"
   ],
   "id": "e499596a38ba6c63",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T18:16:41.790014Z",
     "start_time": "2024-09-22T18:16:41.780454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "2e3479928ee20d8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### HYPERPARAMETERS",
   "id": "efc876550aed3728"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T18:00:52.858613Z",
     "start_time": "2024-09-22T18:00:52.852200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = None\n",
    "model_input_size = 224\n"
   ],
   "id": "78c9a849c151aa5b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DATALOADER",
   "id": "68f6493a28f73cb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T18:50:39.518032Z",
     "start_time": "2024-09-22T18:50:39.449828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FacialKeyPointsDataset(Dataset):\n",
    "    def __init__(self, csv_file_path = r'data/training_frames_keypoints.csv', split = 'training',device=torch.device('cpu')):  \n",
    "        super().__init__()\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.split = split\n",
    "        self.df = pd.read_csv(self.csv_file_path)\n",
    "        # print(self.df)    -->1\n",
    "        self.normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],   #[r,g,b]\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, original_size = self.get_img(idx)\n",
    "        facial_keypoints = self.get_keypoints(index = idx, original_size = original_size)\n",
    "        return img, facial_keypoints\n",
    "    \n",
    "    \n",
    "    def get_img(self, index):    # to get img from  training folder using the keypoints df\n",
    "        # print(self.df.iloc[index,0])   # --> 3\n",
    "        # print(os.path.join(os.getcwd(), 'data', self.split, self.df.iloc[index,0]))   # ---> 4\n",
    "        img_path = os.path.join(os.path.join(os.getcwd(), 'data', self.split, self.df.iloc[index,0]))\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        original_size = img.size\n",
    "        # print(original_size)    # ---> 5\n",
    "        \n",
    "        #pre-process image  ( normalizing and then converting to tensors)\n",
    "        img = img.resize((model_input_size, model_input_size))\n",
    "        # print(img.size)\n",
    "        # print(np.asarray(img))\n",
    "        img = np.asarray(img)/255.0  #range of pixel value is between 0(black) and 255(white), we normalize it to [0,1]\n",
    "        # print(img.shape)  ---> (224,224,3)  i.e ( height , width, channels(RGB))\n",
    "        \n",
    "        \n",
    "        #but in pytorch image_tensor should nbe represented in standard form ( batch,channel, width,height), to solve it we use permute \n",
    "        img = torch.tensor(img).permute(2,0,1).unsqueeze(0)\n",
    "        # print(img.shape)    --> torch.Size([1, 3, 224, 224])\n",
    "        img = self.normalize(img)\n",
    "        # print(img)\n",
    "        return img.to(self.device), original_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_keypoints(self, index,original_size):\n",
    "        kp = self.df.iloc[index, 1:].to_numpy().astype(np.float32)  # since kp_x,y is list ,we cant divide it by int . So, we use broadcasting concept in numpy\n",
    "        kp_x = kp[0::2] / original_size[0]\n",
    "        kp_y = kp[1::2] / original_size[1]\n",
    "        kp = np.concatenate([kp_x, kp_y])  # required ip to the model \n",
    "        print(type(kp))\n",
    "        # print(kp)\n",
    "        return torch.tensor(kp).to(self.device)\n",
    "    \n",
    "    \n",
    "    def load_img(self, index):\n",
    "        img_path = os.path.join(os.getcwd(), 'data', self.split, self.df.iloc[index,0])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((model_input_size, model_input_size))\n",
    "        return np.asarray(img) / 255.0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "training_data = FacialKeyPointsDataset(device=device)\n",
    "# training_data[0]   #-->2\n",
    "test_data = FacialKeyPointsDataset(csv_file_path=r'data/test_frames_keypoints.csv', split='test', device=device)"
   ],
   "id": "22ef20c090cea33c",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:50:25.774216Z",
     "start_time": "2024-09-22T17:50:25.635895Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "12f10ad9e450fc22",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:50:26.452947Z",
     "start_time": "2024-09-22T17:50:26.448864Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d86950b7c80bfc6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/romankasichhwa/Desktop/Facial_key_points/notebook\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "260e940c86728f12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
